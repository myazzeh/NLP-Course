{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOThLWr0q322QzDnbzi2Z0z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myazzeh/NLP-Course/blob/main/Sequence_Learning/NLP_RNN_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Import necessary libraries**#"
      ],
      "metadata": {
        "id": "rdj_5W8kkCh2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsYJX_dWJk9f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import keras\n",
        "from keras.layers import Embedding, Flatten, SimpleRNN, Dense\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.utils import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Load datasets from github and split them to input and output**#"
      ],
      "metadata": {
        "id": "r-97e9nBeyQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df= pd.read_csv('https://raw.githubusercontent.com/myazzeh/NLP-Course/main/datasets/fake_news_train.csv')\n",
        "test_df= pd.read_csv('https://raw.githubusercontent.com/myazzeh/NLP-Course/main/datasets/fake_news_test.csv')"
      ],
      "metadata": {
        "id": "_NwICagPK3PP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train= train_df['claim_s'], train_df['fake_flag']\n",
        "x_test, y_test= test_df['claim_s'], test_df['fake_flag']"
      ],
      "metadata": {
        "id": "yr8lrhrOLH_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Apply Tokenization and Align all text sequences**#\n",
        "num_words parameter in Tokenizer returns the most n frequent words that will appear in the text sequences."
      ],
      "metadata": {
        "id": "cx8XJxDDhOkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tok = Tokenizer(num_words=6000, oov_token='[UNK]')\n",
        "tok.fit_on_texts (x_train)\n",
        "train_seq= tok.texts_to_sequences(x_train)\n",
        "test_seq= tok.texts_to_sequences(x_test)\n",
        "print (f'size of vocab is {len(tok.word_index)}')"
      ],
      "metadata": {
        "id": "DrjZ2AicLb26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_leng= 10\n",
        "vocab= len(tok.word_index)\n",
        "embd_size= 100\n",
        "train_seq= pad_sequences(train_seq, maxlen= max_seq_leng, padding ='post', truncating='post')\n",
        "test_seq= pad_sequences(test_seq, maxlen= max_seq_leng, padding = 'post', truncating='post')\n",
        "train_seq[0:4]"
      ],
      "metadata": {
        "id": "fxNAoPGjN6PE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Text Classification Model 1 using one RNN layer**#"
      ],
      "metadata": {
        "id": "QAgTzbGRis6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model= Sequential()\n",
        "model.add(Embedding(input_dim= vocab , output_dim= embd_size, input_length= max_seq_leng))\n",
        "model.add(SimpleRNN(units = embd_size, return_sequences = False))\n",
        "model.add(Dense(30))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "oQ5aP9_FOXaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_seq, y_train, epochs=10, validation_data=(test_seq, y_test) )"
      ],
      "metadata": {
        "id": "vkhKkRupRl90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "prd = model.predict(test_seq)\n",
        "[1 if x>=0.5 else 0 for x in prd]"
      ],
      "metadata": {
        "id": "3JUkGDEzSTO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Text Classification Model 2 using one Bidirectional RNN layer**#"
      ],
      "metadata": {
        "id": "wgK8it98i491"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Bidirectional, Average\n",
        "model= Sequential()\n",
        "model.add(Embedding(input_dim=vocab , output_dim= embd_size, input_length= max_seq_leng))\n",
        "model.add(Bidirectional(SimpleRNN(units= embd_size, return_sequences=True)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_seq, y_train, epochs=10, validation_data=(test_seq, y_test) )"
      ],
      "metadata": {
        "id": "R8lRuaTZTShn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Text Classification Model 3 using Stacked RNN layers**#"
      ],
      "metadata": {
        "id": "rzS67t_Li-a-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Bidirectional\n",
        "model= Sequential()\n",
        "model.add(Embedding(input_dim=vocab , output_dim= embd_size, input_length= max_seq_leng))\n",
        "model.add(SimpleRNN(units= embd_size, return_sequences=True))\n",
        "model.add(SimpleRNN(units= embd_size, return_sequences=True))\n",
        "model.add(SimpleRNN(units= embd_size, return_sequences=False))\n",
        "model.add(Dense(30))\n",
        "model.add(Dense(1))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_seq, y_train, epochs=10, validation_data=(test_seq, y_test) )"
      ],
      "metadata": {
        "id": "JG6YRmRRcWxH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}