{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Load the necessary Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzaply2S692s",
        "outputId": "d3b72083-407d-4ef8-ee01-2fbef23651d9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import ARLSTem\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Load Training and testing Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmbawA5a7ETj"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('Train.csv')\n",
        "df_test = pd.read_csv('Test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Clean Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXfcVQK07X5L"
      },
      "outputs": [],
      "source": [
        "def clean_text(tweet):\n",
        "  \n",
        "  text = re.sub(\":\",\"\", tweet)\n",
        "  text = re.sub(\"\\d+\", \"\", text)\n",
        "  text = re.sub(\"\\.+\", \"\", text)\n",
        "  text = remove_emoji(text)\n",
        "  emoji_pattern = re.compile(\"[\"\n",
        "  u\"\\U0001F600-\\U0001F64F\" # emoticons\n",
        "  u\"\\U0001F300-\\U0001F5FF\" # symbols & pictographs\n",
        "  u\"\\U0001F680-\\U0001F6FF\" # transport & map symbols\n",
        "  u\"\\U0001F1E0-\\U0001F1FF\" # flags (iOS)\n",
        "  u\"\\U00002702-\\U000027B0\"\n",
        "  u\"\\U000024C2-\\U0001F251\"\n",
        "  \"]+\", flags=re.UNICODE)\n",
        "  text = emoji_pattern.sub(r'', text)\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DomIFNgg7eAc"
      },
      "outputs": [],
      "source": [
        "df_train['claim_s'] = df_train['claim_s'].apply(clean_text)\n",
        "df_test['claim_s'] = df_test['claim_s'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Convert DataFrame to a list for BOW and TF-IDF vectorization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Usually we use CountVectorizer or TFidfVectorizer Class in sklearn.feature_extraction.text sub library.\n",
        "CountVectorizer object call function fit_transform that accepts List of Strings, where each string represents sentence or any text fragment such as document or paragraph. Then, it returns matrix of numbers\n",
        "Each row represents embedding vector of the sentence or text fragment.\n",
        "Each column represent vector of each word or token.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ex-kGN787os7"
      },
      "outputs": [],
      "source": [
        "X_train = df_train['claim_s'].to_list()\n",
        "y_train= df_train['fake_flag']\n",
        "\n",
        "X_test = df_test['claim_s'].to_list()\n",
        "y_test = df_test['fake_flag']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4zsSjgeKyKr"
      },
      "outputs": [],
      "source": [
        "#vectorizer = CountVectorizer() #option 1: BOW\n",
        "vectorizer = TfidfVectorizer() #option 2: TF-IDF\n",
        "\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)\n",
        "feature_names = vectorizer.get_feature_names_out() #get featurenames or tokens in the vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6tCo6o6KyjS"
      },
      "outputs": [],
      "source": [
        "df1 = pd.DataFrame(X_train.toarray(), columns = feature_names)\n",
        "df2 = pd.DataFrame(X_test.toarray(), columns = feature_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Build Machine Learning Algorithm to classify news as fake or not**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKK5uXj1Kyly"
      },
      "outputs": [],
      "source": [
        "# Machine learning model to classify news as fake or not\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(df1, df_train['fake_flag'])\n",
        "prd = lr.predict(df2)\n",
        "print(accuracy_score(df_test['fake_flag'] , prd ))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
